"""
é€å¹³æœºæ¢°åŸç†è¯¾ç¨‹æ™ºèƒ½ä½“ Agent
åŸºäº LangGraph æ„å»ºçš„æ•™è‚²é¢†åŸŸä¸“ç”¨ Agent
åŠŸèƒ½ï¼š
1. ä¸“ä¸šé—®ç­” - å›ç­”é€å¹³æœºæ¢°ç›¸å…³é—®é¢˜
2. ç”Ÿæˆç»ƒä¹ é¢˜ - æ ¹æ®ç« èŠ‚å†…å®¹ç”Ÿæˆé—®ç­”/é€‰æ‹©é¢˜
3. ä½œä¸šæ‰¹æ”¹ - è¯„ä¼°å­¦ç”Ÿç­”æ¡ˆå¹¶ç»™å‡ºåé¦ˆ
4. çŸ¥è¯†æ£€ç´¢ - ä»è¯¾ä»¶å’Œæ•™æä¸­æ£€ç´¢ç›¸å…³å†…å®¹

ä½œè€…: Claude
æ—¥æœŸ: 2024
"""

import os
import json
import logging
import operator
from typing import List, Dict, Any, Optional, TypedDict, Annotated, Literal, Union
from pathlib import Path
from dataclasses import dataclass, field
from enum import Enum

# LangGraph æ ¸å¿ƒç»„ä»¶
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

# LangChain ç»„ä»¶
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain_openai import ChatOpenAI
from langchain_core.documents import Document
from multimodel_rag import MultiDocumentKnowledgeBase
# æ—¥å¿—é…ç½®
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


# ================================
# 1. çŠ¶æ€å®šä¹‰
# ================================

class IntentType(str, Enum):
    """ç”¨æˆ·æ„å›¾ç±»å‹"""
    QA = "qa"  # é—®ç­”
    GENERATE_QUESTIONS = "generate"  # ç”Ÿæˆç»ƒä¹ é¢˜
    GRADE_HOMEWORK = "grade"  # æ‰¹æ”¹ä½œä¸š
    SUMMARY = "summary"  # ç« èŠ‚æ€»ç»“
    UNKNOWN = "unknown"  # æœªçŸ¥æ„å›¾


@dataclass
class QuestionItem:
    """ç»ƒä¹ é¢˜æ•°æ®ç»“æ„"""
    question_type: str  # é¢˜å‹: choice/fill_blank/short_answer/calculation
    question: str  # é¢˜ç›®å†…å®¹
    options: List[str] = field(default_factory=list)  # é€‰æ‹©é¢˜é€‰é¡¹
    answer: str = ""  # æ ‡å‡†ç­”æ¡ˆ
    explanation: str = ""  # ç­”æ¡ˆè§£æ
    difficulty: str = "medium"  # éš¾åº¦: easy/medium/hard
    knowledge_point: str = ""  # çŸ¥è¯†ç‚¹


@dataclass
class GradingResult:
    """æ‰¹æ”¹ç»“æœæ•°æ®ç»“æ„"""
    score: float  # å¾—åˆ† (0-100)
    feedback: str  # åé¦ˆæ„è§
    correct_points: List[str]  # æ­£ç¡®çš„ç‚¹
    wrong_points: List[str]  # é”™è¯¯çš„ç‚¹
    suggestions: List[str]  # æ”¹è¿›å»ºè®®
    reference_answer: str = ""  # å‚è€ƒç­”æ¡ˆ


class AgentState(TypedDict):
    """Agent çŠ¶æ€å®šä¹‰"""
    # è¾“å…¥
    user_input: str  # ç”¨æˆ·è¾“å…¥
    session_id: str  # ä¼šè¯ID

    # æ„å›¾è¯†åˆ«
    intent: IntentType  # è¯†åˆ«çš„æ„å›¾
    intent_confidence: float  # æ„å›¾ç½®ä¿¡åº¦

    # ä¸Šä¸‹æ–‡
    chat_history: Annotated[List[BaseMessage], operator.add]  # å¯¹è¯å†å²
    retrieved_docs: List[Dict[str, Any]]  # æ£€ç´¢åˆ°çš„æ–‡æ¡£
    retrieved_images: List[str]  # æ£€ç´¢åˆ°çš„å›¾ç‰‡è·¯å¾„

    # é—®ç­”ç›¸å…³
    qa_answer: str  # é—®ç­”å›ç­”
    qa_confidence: float  # å›ç­”ç½®ä¿¡åº¦
    qa_sources: List[Dict[str, Any]]  # å›ç­”æ¥æº

    # ç»ƒä¹ é¢˜ç”Ÿæˆç›¸å…³
    chapter_info: str  # ç« èŠ‚ä¿¡æ¯
    question_type: str  # é¢˜ç›®ç±»å‹
    question_count: int  # é¢˜ç›®æ•°é‡
    difficulty: str  # éš¾åº¦è¦æ±‚
    generated_questions: List[Dict[str, Any]]  # ç”Ÿæˆçš„ç»ƒä¹ é¢˜

    # ä½œä¸šæ‰¹æ”¹ç›¸å…³
    student_answer: str  # å­¦ç”Ÿç­”æ¡ˆ
    reference_content: str  # å‚è€ƒå†…å®¹/æ ‡å‡†ç­”æ¡ˆ
    grading_result: Dict[str, Any]  # æ‰¹æ”¹ç»“æœ

    # è¾“å‡º
    final_response: str  # æœ€ç»ˆå›å¤
    error_message: str  # é”™è¯¯ä¿¡æ¯


# ================================
# 2. çŸ¥è¯†åº“æ¥å£é€‚é…å™¨
# ================================

class KnowledgeBaseAdapter:
    """
    çŸ¥è¯†åº“é€‚é…å™¨ - å°è£…ä¸ç°æœ‰ RAG ç³»ç»Ÿçš„äº¤äº’
    å¯ä»¥æ›¿æ¢ä¸ºç”¨æˆ·è‡ªå·±çš„å¾®è°ƒæ¨¡å‹å’ŒçŸ¥è¯†åº“
    """

    def __init__(self, knowledge_base=None, custom_llm=None):
        """
        åˆå§‹åŒ–çŸ¥è¯†åº“é€‚é…å™¨

        Args:
            knowledge_base: ç”¨æˆ·æä¾›çš„çŸ¥è¯†åº“å®ä¾‹ (MultiDocumentKnowledgeBase)
            custom_llm: ç”¨æˆ·å¾®è°ƒçš„å¤§æ¨¡å‹å®ä¾‹
        """
        self.kb = knowledge_base
        self.custom_llm = custom_llm

    def search(self, question: str, k: int = 8) -> List[Document]:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        if self.kb is None:
            logger.warning("çŸ¥è¯†åº“æœªåˆå§‹åŒ–")
            return []
        try:
            return self.kb.search(question, k=k)
        except Exception as e:
            logger.error(f"æ£€ç´¢å¤±è´¥: {e}")
            return []

    def query_with_rerank(self, question: str, session_id: str, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œå¸¦é‡æ’åºçš„æŸ¥è¯¢"""
        if self.kb is None:
            return {"answer": "", "sources": [], "confidence": 0.0}

        try:
            return self.kb.query(question, session_id=session_id, **kwargs)
        except Exception as e:
            logger.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
            return {"answer": f"æŸ¥è¯¢å‡ºé”™: {e}", "sources": [], "confidence": 0.0}

    def get_chapter_content(self, chapter_name: str) -> str:
        """è·å–æŒ‡å®šç« èŠ‚çš„å†…å®¹"""
        if self.kb is None:
            return ""

        # æ£€ç´¢ç« èŠ‚ç›¸å…³å†…å®¹
        docs = self.search(f"{chapter_name} å†…å®¹ æ¦‚è¿°", k=10)
        if docs:
            return "\n\n".join([doc.page_content for doc in docs])
        return ""

    def get_llm(self):
        """è·å–LLMå®ä¾‹ï¼ˆä¼˜å…ˆä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰çš„å¾®è°ƒæ¨¡å‹ï¼‰"""
        if self.custom_llm:
            return self.custom_llm
        # è¿”å›Noneï¼Œç”±è°ƒç”¨æ–¹å¤„ç†
        return None


# ================================
# 3. Agent èŠ‚ç‚¹å®ç°
# ================================

class TurbineCourseAgent:
    """é€å¹³æœºæ¢°åŸç†è¯¾ç¨‹æ™ºèƒ½ä½“"""

    def __init__(
            self,
            knowledge_base=None,
            llm: Optional[ChatOpenAI] = None,
            custom_fine_tuned_llm=None
    ):
        """
        åˆå§‹åŒ– Agent

        Args:
            knowledge_base: MultiDocumentKnowledgeBase å®ä¾‹
            llm: é»˜è®¤ LLM (å¦‚ ChatOpenAI)
            custom_fine_tuned_llm: ç”¨æˆ·å¾®è°ƒçš„ä¸“ä¸šé¢†åŸŸæ¨¡å‹
        """
        # çŸ¥è¯†åº“é€‚é…å™¨
        self.kb_adapter = KnowledgeBaseAdapter(knowledge_base, custom_fine_tuned_llm)

        # LLM é…ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨å¾®è°ƒæ¨¡å‹ï¼‰
        if custom_fine_tuned_llm:
            self.llm = custom_fine_tuned_llm
            logger.info("ä½¿ç”¨ç”¨æˆ·æä¾›çš„å¾®è°ƒæ¨¡å‹")
        elif llm:
            self.llm = llm
            logger.info("ä½¿ç”¨é»˜è®¤ LLM")
        else:
            raise ValueError("å¿…é¡»æä¾› llm æˆ– custom_fine_tuned_llm å‚æ•°")

        # æ„å»º Graph
        self.graph = self._build_graph()

        # æ£€æŸ¥ç‚¹ä¿å­˜å™¨ï¼ˆç”¨äºå¯¹è¯æŒä¹…åŒ–ï¼‰
        self.memory = MemorySaver()

        # ç¼–è¯‘ Graph
        self.app = self.graph.compile(checkpointer=self.memory)

        logger.info("é€å¹³æœºæ¢°åŸç†è¯¾ç¨‹æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")

    def _build_graph(self) -> StateGraph:
        """æ„å»º LangGraph å·¥ä½œæµ"""

        # åˆ›å»ºçŠ¶æ€å›¾
        workflow = StateGraph(AgentState)

        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("intent_classifier", self._intent_classifier_node)
        workflow.add_node("retriever", self._retriever_node)
        workflow.add_node("qa_node", self._qa_node)
        workflow.add_node("question_generator", self._question_generator_node)
        workflow.add_node("homework_grader", self._homework_grader_node)
        workflow.add_node("summary_node", self._summary_node)
        workflow.add_node("response_formatter", self._response_formatter_node)
        workflow.add_node("error_handler", self._error_handler_node)

        # è®¾ç½®å…¥å£
        workflow.set_entry_point("intent_classifier")

        # æ·»åŠ æ¡ä»¶è¾¹ - æ ¹æ®æ„å›¾è·¯ç”±
        workflow.add_conditional_edges(
            "intent_classifier",
            self._route_by_intent,
            {
                "qa": "retriever",
                "generate": "retriever",
                "grade": "homework_grader",
                "summary": "retriever",
                "error": "error_handler"
            }
        )

        # æ£€ç´¢åçš„è·¯ç”±
        workflow.add_conditional_edges(
            "retriever",
            self._route_after_retrieval,
            {
                "qa": "qa_node",
                "generate": "question_generator",
                "summary": "summary_node"
            }
        )

        # å„èŠ‚ç‚¹åˆ°æ ¼å¼åŒ–è¾“å‡º
        workflow.add_edge("qa_node", "response_formatter")
        workflow.add_edge("question_generator", "response_formatter")
        workflow.add_edge("homework_grader", "response_formatter")
        workflow.add_edge("summary_node", "response_formatter")
        workflow.add_edge("error_handler", "response_formatter")

        # æ ¼å¼åŒ–è¾“å‡ºåˆ°ç»“æŸ
        workflow.add_edge("response_formatter", END)

        return workflow

    # --------------------------------
    # èŠ‚ç‚¹å®ç°
    # --------------------------------

    def _intent_classifier_node(self, state: AgentState) -> AgentState:
        """æ„å›¾è¯†åˆ«èŠ‚ç‚¹"""
        user_input = state["user_input"]

        # æ„å›¾åˆ†ç±»æç¤ºè¯
        intent_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªé€å¹³æœºæ¢°åŸç†è¯¾ç¨‹çš„æ•™å­¦åŠ©æ‰‹ï¼Œè´Ÿè´£è¯†åˆ«ç”¨æˆ·çš„æ„å›¾ã€‚

è¯·æ ¹æ®ç”¨æˆ·è¾“å…¥ï¼Œåˆ¤æ–­å…¶æ„å›¾ç±»å‹ï¼Œåªèƒ½è¿”å›ä»¥ä¸‹JSONæ ¼å¼ï¼š

```json
{{
    "intent": "æ„å›¾ç±»å‹",
    "confidence": ç½®ä¿¡åº¦(0-1),
    "extracted_info": {{
        "chapter": "æå–çš„ç« èŠ‚ä¿¡æ¯ï¼ˆå¦‚æœ‰ï¼‰",
        "question_type": "é¢˜ç›®ç±»å‹ï¼ˆå¦‚æœ‰ï¼‰: choice/fill_blank/short_answer/calculation",
        "count": é¢˜ç›®æ•°é‡ï¼ˆå¦‚æœ‰ï¼‰,
        "difficulty": "éš¾åº¦ï¼ˆå¦‚æœ‰ï¼‰: easy/medium/hard",
        "student_answer": "å­¦ç”Ÿç­”æ¡ˆï¼ˆå¦‚æœ‰ï¼‰"
    }}
}}
```

æ„å›¾ç±»å‹è¯´æ˜ï¼š
- "qa": ç”¨æˆ·åœ¨æé—®æˆ–è¯¢é—®çŸ¥è¯†ç‚¹ï¼ˆå¦‚ï¼šä»€ä¹ˆæ˜¯é€å¹³ï¼Ÿè½´æµå¼å‹ç¼©æœºçš„å·¥ä½œåŸç†ï¼Ÿï¼‰
- "generate": ç”¨æˆ·è¦æ±‚ç”Ÿæˆç»ƒä¹ é¢˜ï¼ˆå¦‚ï¼šç»™æˆ‘å‡º5é“é€‰æ‹©é¢˜ã€ç”Ÿæˆç¬¬ä¸‰ç« çš„è®¡ç®—é¢˜ï¼‰
- "grade": ç”¨æˆ·è¦æ±‚æ‰¹æ”¹ä½œä¸šæˆ–è¯„ä¼°ç­”æ¡ˆï¼ˆå¦‚ï¼šå¸®æˆ‘æ‰¹æ”¹è¿™é“é¢˜ã€æˆ‘çš„ç­”æ¡ˆå¯¹å—ï¼‰
- "summary": ç”¨æˆ·è¦æ±‚æ€»ç»“ç« èŠ‚å†…å®¹ï¼ˆå¦‚ï¼šæ€»ç»“ç¬¬äºŒç« ã€å½’çº³çŸ¥è¯†ç‚¹ï¼‰
- "unknown": æ— æ³•è¯†åˆ«çš„æ„å›¾

æ³¨æ„ï¼šåªè¿”å›JSONï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚"""),
            ("user", "{input}")
        ])

        try:
            chain = intent_prompt | self.llm | StrOutputParser()
            result = chain.invoke({"input": user_input})

            # ã€ä¿®æ”¹å¼€å§‹ã€‘ä½¿ç”¨æ­£åˆ™æå– JSONï¼Œå¢å¼ºå¥å£®æ€§
            import re
            try:
                # å°è¯•åŒ¹é…å¤§æ‹¬å· {} åŒ…è£¹çš„å†…å®¹
                match = re.search(r"(\{.*\})", result, re.DOTALL)
                if match:
                    json_str = match.group(1)
                    parsed = json.loads(json_str)
                else:
                    # å…œåº•ï¼šå°è¯•ç›´æ¥è§£æ
                    parsed = json.loads(result)
            except json.JSONDecodeError:
                logger.warning(f"JSON è§£æå¤±è´¥ï¼ŒåŸå§‹ç»“æœ: {result}")
                # è§£æå¤±è´¥æ—¶ï¼Œé»˜è®¤è®¾ä¸º QA æ¨¡å¼ï¼Œé¿å…æµç¨‹ä¸­æ–­
                parsed = {"intent": "qa", "confidence": 0.5}

            intent_str = parsed.get("intent", "unknown")
            confidence = parsed.get("confidence", 0.5)
            extracted = parsed.get("extracted_info", {})

            # æ˜ å°„æ„å›¾
            intent_map = {
                "qa": IntentType.QA,
                "generate": IntentType.GENERATE_QUESTIONS,
                "grade": IntentType.GRADE_HOMEWORK,
                "summary": IntentType.SUMMARY,
                "unknown": IntentType.UNKNOWN
            }

            intent = intent_map.get(intent_str, IntentType.UNKNOWN)

            logger.info(f"è¯†åˆ«æ„å›¾: {intent.value}, ç½®ä¿¡åº¦: {confidence}")

            return {
                **state,
                "intent": intent,
                "intent_confidence": confidence,
                "chapter_info": extracted.get("chapter", ""),
                "question_type": extracted.get("question_type", "short_answer"),
                "question_count": extracted.get("count", 5),
                "difficulty": extracted.get("difficulty", "medium"),
                "student_answer": extracted.get("student_answer", state.get("student_answer", ""))
            }

        except Exception as e:
            logger.error(f"æ„å›¾è¯†åˆ«å¤±è´¥: {e}")
            return {
                **state,
                "intent": IntentType.QA,  # é»˜è®¤å½“ä½œé—®ç­”
                "intent_confidence": 0.3,
                "error_message": f"æ„å›¾è¯†åˆ«å‡ºç°é—®é¢˜: {str(e)}"
            }

    def _retriever_node(self, state: AgentState) -> AgentState:
        """æ£€ç´¢èŠ‚ç‚¹ - ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³å†…å®¹"""
        user_input = state["user_input"]
        chapter_info = state.get("chapter_info", "")

        # æ„å»ºæ£€ç´¢æŸ¥è¯¢
        if chapter_info:
            query = f"{chapter_info} {user_input}"
        else:
            query = user_input

        try:
            # ä½¿ç”¨çŸ¥è¯†åº“æ£€ç´¢
            docs = self.kb_adapter.search(query, k=10)

            retrieved_docs = []
            retrieved_images = []

            for doc in docs:
                doc_info = {
                    "content": doc.page_content,
                    "source": doc.metadata.get("file_name", "Unknown"),
                    "page": doc.metadata.get("page_number", "N/A"),
                    "chunk_id": doc.metadata.get("chunk_id", "")
                }
                retrieved_docs.append(doc_info)

                # æå–å›¾ç‰‡è·¯å¾„
                img_paths = doc.metadata.get("image_paths", [])
                if isinstance(img_paths, str):
                    try:
                        import ast
                        img_paths = ast.literal_eval(img_paths)
                    except:
                        img_paths = []

                for img_path in img_paths:
                    if img_path and Path(img_path).exists():
                        retrieved_images.append(img_path)

            logger.info(f"æ£€ç´¢åˆ° {len(retrieved_docs)} ä¸ªæ–‡æ¡£ç‰‡æ®µ, {len(retrieved_images)} å¼ å›¾ç‰‡")

            return {
                **state,
                "retrieved_docs": retrieved_docs,
                "retrieved_images": retrieved_images[:3]  # é™åˆ¶å›¾ç‰‡æ•°é‡
            }

        except Exception as e:
            logger.error(f"æ£€ç´¢å¤±è´¥: {e}")
            return {
                **state,
                "retrieved_docs": [],
                "retrieved_images": [],
                "error_message": f"çŸ¥è¯†æ£€ç´¢å¤±è´¥: {str(e)}"
            }

    def _qa_node(self, state: AgentState) -> AgentState:
        """é—®ç­”èŠ‚ç‚¹ - å›ç­”ç”¨æˆ·é—®é¢˜"""
        user_input = state["user_input"]
        retrieved_docs = state.get("retrieved_docs", [])
        chat_history = state.get("chat_history", [])

        # æ„å»ºä¸Šä¸‹æ–‡
        context_parts = []
        for doc in retrieved_docs[:7]:  # å–å‰7ä¸ªæ–‡æ¡£
            source_info = f"[æ¥æº: {doc['source']}, é¡µç : {doc['page']}]"
            context_parts.append(f"{doc['content']}\n{source_info}")

        context = "\n\n---\n\n".join(context_parts)

        # é—®ç­”æç¤ºè¯
        qa_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯é€å¹³æœºæ¢°åŸç†è¯¾ç¨‹çš„ä¸“ä¸šæ•™å­¦åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæä¾›çš„è¯¾ç¨‹èµ„æ–™ï¼Œå‡†ç¡®å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚

ã€å›ç­”åŸåˆ™ã€‘
1. ç­”æ¡ˆå¿…é¡»åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡èµ„æ–™ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯
2. ä½¿ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€ï¼Œé€‚åˆæœ¬ç§‘ç”Ÿç†è§£
3. å¦‚æœ‰å¿…è¦ï¼Œå¯ä»¥ä½¿ç”¨å…¬å¼ã€å›¾ç¤ºè¯´æ˜ï¼ˆç”¨æ–‡å­—æè¿°ï¼‰
4. å¦‚æœèµ„æ–™ä¸è¶³ä»¥å›ç­”ï¼Œè¯·è¯šå®è¯´æ˜
5. é¼“åŠ±å­¦ç”Ÿæ·±å…¥æ€è€ƒï¼Œå¯ä»¥æä¾›ç›¸å…³å»¶ä¼¸é—®é¢˜

ã€è¯¾ç¨‹èƒŒæ™¯ã€‘
é€å¹³æœºæ¢°åŸç†æ¶µç›–ï¼š
- é€å¹³æœºæ¢°åŸºæœ¬æ¦‚å¿µä¸åˆ†ç±»
- å¶è½®æœºæ¢°çš„åŸºæœ¬æ–¹ç¨‹
- è½´æµå¼å‹ç¼©æœº/é€å¹³çš„å·¥ä½œåŸç†
- ç¦»å¿ƒå¼å‹ç¼©æœºçš„å·¥ä½œåŸç†
- çº§çš„æ€§èƒ½ä¸è°ƒèŠ‚
- å¤šçº§é€å¹³æœºæ¢°

ã€ä¸Šä¸‹æ–‡èµ„æ–™ã€‘
{context}"""),
            MessagesPlaceholder(variable_name="history"),
            ("user", "{question}")
        ])

        try:
            chain = qa_prompt | self.llm | StrOutputParser()
            answer = chain.invoke({
                "context": context if context else "ï¼ˆæš‚æ— ç›¸å…³èµ„æ–™ï¼Œå°†åŸºäºé€šç”¨çŸ¥è¯†å›ç­”ï¼‰",
                "history": chat_history[-6:] if chat_history else [],
                "question": user_input
            })
            
            # æ‰“å°å‡ºæ¥çœ‹çœ‹ç©¶ç«Ÿ LLM è¿”å›äº†ä»€ä¹ˆ
            logger.info(f"LLM åŸå§‹å›ç­”å†…å®¹: [{answer}]") 
            
            if not answer:
                answer = "é”™è¯¯ï¼šLLM è¿”å›äº†ç©ºå†…å®¹ï¼Œè¯·æ£€æŸ¥ API Key æˆ– æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®ã€‚"

            # è®¡ç®—ç½®ä¿¡åº¦
            confidence = 0.8 if retrieved_docs else 0.4

            # æ•´ç†æ¥æº
            sources = []
            seen = set()
            for doc in retrieved_docs[:5]:
                key = f"{doc['source']}_{doc['page']}"
                if key not in seen:
                    sources.append({
                        "file": doc['source'],
                        "page": doc['page']
                    })
                    seen.add(key)

            logger.info(f"é—®ç­”å®Œæˆï¼Œç½®ä¿¡åº¦: {confidence}")

            return {
                **state,
                "qa_answer": answer,
                "qa_confidence": confidence,
                "qa_sources": sources,
                "chat_history": chat_history + [
                    HumanMessage(content=user_input),
                    AIMessage(content=answer)
                ]
            }

        except Exception as e:
            logger.error(f"é—®ç­”å¤±è´¥: {e}")
            return {
                **state,
                "qa_answer": f"æŠ±æ­‰ï¼Œå›ç­”æ‚¨çš„é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {str(e)}",
                "qa_confidence": 0.0,
                "qa_sources": []
            }

    def _question_generator_node(self, state: AgentState) -> AgentState:
        """ç»ƒä¹ é¢˜ç”ŸæˆèŠ‚ç‚¹"""
        chapter_info = state.get("chapter_info", "é€å¹³æœºæ¢°åŸç†")
        question_type = state.get("question_type", "short_answer")
        question_count = state.get("question_count", 5)
        difficulty = state.get("difficulty", "medium")
        retrieved_docs = state.get("retrieved_docs", [])

        # æ„å»ºä¸Šä¸‹æ–‡
        context = "\n\n".join([doc["content"] for doc in retrieved_docs[:5]])

        # é¢˜å‹è¯´æ˜
        type_instructions = {
            "choice": "é€‰æ‹©é¢˜ï¼ˆå•é€‰ï¼‰ï¼Œéœ€è¦æä¾›4ä¸ªé€‰é¡¹A/B/C/D",
            "fill_blank": "å¡«ç©ºé¢˜ï¼Œç”¨___è¡¨ç¤ºç©ºç™½å¤„",
            "short_answer": "ç®€ç­”é¢˜ï¼Œéœ€è¦ç®€çŸ­å›ç­”ï¼ˆ50-150å­—ï¼‰",
            "calculation": "è®¡ç®—é¢˜ï¼Œéœ€è¦ç»™å‡ºè®¡ç®—æ­¥éª¤å’Œç­”æ¡ˆ"
        }

        difficulty_desc = {
            "easy": "åŸºç¡€æ¦‚å¿µé¢˜ï¼Œç›´æ¥è€ƒæŸ¥å®šä¹‰å’ŒåŸºæœ¬åŸç†",
            "medium": "ä¸­ç­‰éš¾åº¦ï¼Œéœ€è¦ç†è§£å’Œç®€å•åº”ç”¨",
            "hard": "è¾ƒéš¾ï¼Œéœ€è¦ç»¼åˆåˆ†æå’Œçµæ´»è¿ç”¨"
        }

        # ç”Ÿæˆæç¤ºè¯
        gen_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯é€å¹³æœºæ¢°åŸç†è¯¾ç¨‹çš„å‡ºé¢˜ä¸“å®¶ã€‚è¯·æ ¹æ®ç»™å®šçš„è¯¾ç¨‹å†…å®¹å’Œè¦æ±‚ï¼Œç”Ÿæˆé«˜è´¨é‡çš„ç»ƒä¹ é¢˜ã€‚

ã€å‡ºé¢˜è¦æ±‚ã€‘
- ç« èŠ‚/çŸ¥è¯†ç‚¹: {chapter}
- é¢˜å‹: {type_desc}
- æ•°é‡: {count}é“
- éš¾åº¦: {difficulty_desc}

ã€å‚è€ƒèµ„æ–™ã€‘
{context}

ã€è¾“å‡ºæ ¼å¼ã€‘
è¯·ä»¥JSONæ•°ç»„æ ¼å¼è¾“å‡ºï¼Œæ¯é“é¢˜åŒ…å«ï¼š
```json
[
    {{
        "question_type": "é¢˜å‹",
        "question": "é¢˜ç›®å†…å®¹",
        "options": ["A. é€‰é¡¹1", "B. é€‰é¡¹2", "C. é€‰é¡¹3", "D. é€‰é¡¹4"],  // é€‰æ‹©é¢˜å¿…å¡«
        "answer": "æ ‡å‡†ç­”æ¡ˆ",
        "explanation": "ç­”æ¡ˆè§£æ",
        "difficulty": "éš¾åº¦",
        "knowledge_point": "è€ƒæŸ¥çš„çŸ¥è¯†ç‚¹"
    }}
]
```

ã€æ³¨æ„äº‹é¡¹ã€‘
1. é¢˜ç›®è¦ç´§æ‰£é€å¹³æœºæ¢°åŸç†çš„æ ¸å¿ƒçŸ¥è¯†ç‚¹
2. ç­”æ¡ˆè¦å‡†ç¡®ï¼Œè§£æè¦è¯¦ç»†
3. éš¾åº¦è¦ç¬¦åˆè¦æ±‚
4. å¦‚æœæ˜¯è®¡ç®—é¢˜ï¼Œç­”æ¡ˆè¦åŒ…å«å®Œæ•´çš„è®¡ç®—è¿‡ç¨‹"""),
            ("user", "è¯·ç”Ÿæˆ{count}é“å…³äº{chapter}çš„{type_name}ï¼Œéš¾åº¦ä¸º{difficulty}ã€‚")
        ])

        try:
            chain = gen_prompt | self.llm | StrOutputParser()
            result = chain.invoke({
                "chapter": chapter_info,
                "type_desc": type_instructions.get(question_type, "ç®€ç­”é¢˜"),
                "type_name": question_type,
                "count": question_count,
                "difficulty": difficulty,
                "difficulty_desc": difficulty_desc.get(difficulty, "ä¸­ç­‰éš¾åº¦"),
                "context": context if context else "ï¼ˆæ— é¢å¤–å‚è€ƒèµ„æ–™ï¼Œè¯·åŸºäºé€å¹³æœºæ¢°åŸç†é€šç”¨çŸ¥è¯†å‡ºé¢˜ï¼‰"
            })

            # è§£æJSON
            result = result.strip()
            if "```json" in result:
                result = result.split("```json")[1].split("```")[0]
            elif "```" in result:
                result = result.split("```")[1].split("```")[0]

            questions = json.loads(result)

            logger.info(f"æˆåŠŸç”Ÿæˆ {len(questions)} é“ç»ƒä¹ é¢˜")

            return {
                **state,
                "generated_questions": questions
            }

        except json.JSONDecodeError as e:
            logger.error(f"è§£æç»ƒä¹ é¢˜JSONå¤±è´¥: {e}")
            # å°è¯•ç›´æ¥è¿”å›æ–‡æœ¬æ ¼å¼
            return {
                **state,
                "generated_questions": [{"raw_text": result, "parse_error": str(e)}],
                "error_message": "ç»ƒä¹ é¢˜æ ¼å¼è§£æå¤±è´¥ï¼Œå·²è¿”å›åŸå§‹æ–‡æœ¬"
            }
        except Exception as e:
            logger.error(f"ç”Ÿæˆç»ƒä¹ é¢˜å¤±è´¥: {e}")
            return {
                **state,
                "generated_questions": [],
                "error_message": f"ç”Ÿæˆç»ƒä¹ é¢˜å¤±è´¥: {str(e)}"
            }

    def _homework_grader_node(self, state: AgentState) -> AgentState:
        """ä½œä¸šæ‰¹æ”¹èŠ‚ç‚¹"""
        user_input = state["user_input"]
        student_answer = state.get("student_answer", "")
        reference_content = state.get("reference_content", "")

        # å¦‚æœæ²¡æœ‰å•ç‹¬çš„å­¦ç”Ÿç­”æ¡ˆï¼Œå°è¯•ä»ç”¨æˆ·è¾“å…¥ä¸­æå–
        if not student_answer:
            student_answer = user_input

        # æ‰¹æ”¹æç¤ºè¯
        grade_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯é€å¹³æœºæ¢°åŸç†è¯¾ç¨‹çš„ä½œä¸šæ‰¹æ”¹åŠ©æ‰‹ã€‚è¯·å¯¹å­¦ç”Ÿçš„ç­”æ¡ˆè¿›è¡Œä¸“ä¸šã€å®¢è§‚ã€é¼“åŠ±æ€§çš„è¯„ä»·ã€‚

ã€è¯„åˆ†æ ‡å‡†ã€‘
1. æ¦‚å¿µå‡†ç¡®æ€§ï¼ˆ40%ï¼‰: ä¸“ä¸šæœ¯è¯­ä½¿ç”¨æ˜¯å¦æ­£ç¡®ï¼Œæ¦‚å¿µç†è§£æ˜¯å¦å‡†ç¡®
2. é€»è¾‘å®Œæ•´æ€§ï¼ˆ30%ï¼‰: ç­”æ¡ˆæ˜¯å¦å®Œæ•´ï¼Œé€»è¾‘æ˜¯å¦æ¸…æ™°
3. è¡¨è¾¾è§„èŒƒæ€§ï¼ˆ20%ï¼‰: è¡¨è¾¾æ˜¯å¦æ¸…æ™°ï¼Œå…¬å¼ç¬¦å·æ˜¯å¦è§„èŒƒ
4. åˆ›æ–°æ€è€ƒï¼ˆ10%ï¼‰: æ˜¯å¦æœ‰ç‹¬åˆ°è§è§£æˆ–å»¶ä¼¸æ€è€ƒ

ã€è¾“å‡ºæ ¼å¼ã€‘
è¯·ä»¥JSONæ ¼å¼è¾“å‡ºè¯„ä»·ç»“æœï¼š
```json
{{
    "score": å¾—åˆ†(0-100),
    "level": "è¯„çº§(ä¼˜ç§€/è‰¯å¥½/ä¸­ç­‰/åŠæ ¼/ä¸åŠæ ¼)",
    "feedback": "æ€»ä½“è¯„ä»·",
    "correct_points": ["ç­”å¯¹çš„çŸ¥è¯†ç‚¹1", "ç­”å¯¹çš„çŸ¥è¯†ç‚¹2"],
    "wrong_points": ["é”™è¯¯ç‚¹1åŠåŸå› ", "é”™è¯¯ç‚¹2åŠåŸå› "],
    "suggestions": ["æ”¹è¿›å»ºè®®1", "æ”¹è¿›å»ºè®®2"],
    "reference_answer": "å‚è€ƒç­”æ¡ˆæˆ–è¡¥å……è¯´æ˜"
}}
```

ã€æ‰¹æ”¹åŸåˆ™ã€‘
1. å®¢è§‚å…¬æ­£ï¼Œæœ‰ç†æœ‰æ®
2. æŒ‡å‡ºé—®é¢˜çš„åŒæ—¶ç»™äºˆé¼“åŠ±
3. æä¾›å…·ä½“çš„æ”¹è¿›æ–¹å‘
4. å¦‚æœç­”æ¡ˆåŸºæœ¬æ­£ç¡®ä½†è¡¨è¿°ä¸å®Œå–„ï¼Œä¹Ÿè¦è‚¯å®šå­¦ç”Ÿçš„æ€è·¯"""),
            ("user", """ã€å­¦ç”Ÿç­”æ¡ˆã€‘
{student_answer}

ã€å‚è€ƒèµ„æ–™/æ ‡å‡†ç­”æ¡ˆã€‘
{reference}

è¯·æ‰¹æ”¹è¿™ä»½ä½œä¸šã€‚""")
        ])

        try:
            chain = grade_prompt | self.llm | StrOutputParser()
            result = chain.invoke({
                "student_answer": student_answer,
                "reference": reference_content if reference_content else "ï¼ˆæ— æ ‡å‡†ç­”æ¡ˆå‚è€ƒï¼Œè¯·åŸºäºä¸“ä¸šçŸ¥è¯†è¯„åˆ¤ï¼‰"
            })

            # è§£æJSON
            result = result.strip()
            if "```json" in result:
                result = result.split("```json")[1].split("```")[0]
            elif "```" in result:
                result = result.split("```")[1].split("```")[0]

            grading = json.loads(result)

            logger.info(f"æ‰¹æ”¹å®Œæˆï¼Œå¾—åˆ†: {grading.get('score', 'N/A')}")

            return {
                **state,
                "grading_result": grading
            }

        except Exception as e:
            logger.error(f"æ‰¹æ”¹å¤±è´¥: {e}")
            return {
                **state,
                "grading_result": {
                    "score": -1,
                    "feedback": f"æ‰¹æ”¹è¿‡ç¨‹å‡ºç°é”™è¯¯: {str(e)}",
                    "correct_points": [],
                    "wrong_points": [],
                    "suggestions": ["è¯·é‡æ–°æäº¤ä½œä¸š"]
                }
            }

    def _summary_node(self, state: AgentState) -> AgentState:
        """ç« èŠ‚æ€»ç»“èŠ‚ç‚¹"""
        chapter_info = state.get("chapter_info", "")
        retrieved_docs = state.get("retrieved_docs", [])

        # æ„å»ºä¸Šä¸‹æ–‡
        context = "\n\n".join([doc["content"] for doc in retrieved_docs])

        # æ€»ç»“æç¤ºè¯
        summary_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯é€å¹³æœºæ¢°åŸç†è¯¾ç¨‹çš„æ•™å­¦åŠ©æ‰‹ã€‚è¯·æ ¹æ®æä¾›çš„èµ„æ–™ï¼Œå¯¹æŒ‡å®šç« èŠ‚è¿›è¡Œç³»ç»Ÿæ€§æ€»ç»“ã€‚

ã€æ€»ç»“è¦æ±‚ã€‘
1. æç‚¼æ ¸å¿ƒçŸ¥è¯†ç‚¹å’Œé‡è¦æ¦‚å¿µ
2. å½’çº³å…³é”®å…¬å¼å’ŒåŸç†
3. æŒ‡å‡ºå­¦ä¹ é‡ç‚¹å’Œéš¾ç‚¹
4. åˆ—å‡ºå¸¸è§è€ƒç‚¹
5. æä¾›å­¦ä¹ å»ºè®®

ã€è¾“å‡ºæ ¼å¼ã€‘
## {chapter} çŸ¥è¯†ç‚¹æ€»ç»“

### ä¸€ã€æ ¸å¿ƒæ¦‚å¿µ
- æ¦‚å¿µ1: è§£é‡Š
- æ¦‚å¿µ2: è§£é‡Š

### äºŒã€é‡è¦å…¬å¼
- å…¬å¼1: å«ä¹‰è¯´æ˜
- å…¬å¼2: å«ä¹‰è¯´æ˜

### ä¸‰ã€å­¦ä¹ é‡ç‚¹
1. é‡ç‚¹1
2. é‡ç‚¹2

### å››ã€å¸¸è§è€ƒç‚¹
1. è€ƒç‚¹1
2. è€ƒç‚¹2

### äº”ã€å­¦ä¹ å»ºè®®
- å»ºè®®1
- å»ºè®®2"""),
            ("user", """ã€ç« èŠ‚ä¿¡æ¯ã€‘
{chapter}

ã€å‚è€ƒèµ„æ–™ã€‘
{context}

è¯·ç”Ÿæˆè¯¥ç« èŠ‚çš„çŸ¥è¯†ç‚¹æ€»ç»“ã€‚""")
        ])

        try:
            chain = summary_prompt | self.llm | StrOutputParser()
            summary = chain.invoke({
                "chapter": chapter_info if chapter_info else "é€å¹³æœºæ¢°åŸç†",
                "context": context if context else "ï¼ˆæ— é¢å¤–å‚è€ƒèµ„æ–™ï¼‰"
            })

            return {
                **state,
                "qa_answer": summary,
                "qa_confidence": 0.85 if retrieved_docs else 0.6
            }

        except Exception as e:
            logger.error(f"æ€»ç»“ç”Ÿæˆå¤±è´¥: {e}")
            return {
                **state,
                "qa_answer": f"ç”Ÿæˆæ€»ç»“æ—¶å‡ºç°é”™è¯¯: {str(e)}",
                "qa_confidence": 0.0
            }

    def _response_formatter_node(self, state: AgentState) -> AgentState:
        """å“åº”æ ¼å¼åŒ–èŠ‚ç‚¹ - å°†å„èŠ‚ç‚¹è¾“å‡ºæ ¼å¼åŒ–ä¸ºæœ€ç»ˆå“åº”"""
        intent = state.get("intent", IntentType.UNKNOWN)
        error_msg = state.get("error_message", "")

        if error_msg and intent == IntentType.UNKNOWN:
            response = f"âŒ æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°é—®é¢˜ï¼š\n{error_msg}\n\næ‚¨å¯ä»¥å°è¯•ï¼š\n- æé—®é€å¹³æœºæ¢°ç›¸å…³çŸ¥è¯†\n- è®©æˆ‘ç”Ÿæˆç»ƒä¹ é¢˜\n- æäº¤ä½œä¸šè®©æˆ‘æ‰¹æ”¹"

        elif intent == IntentType.QA:
            answer = state.get("qa_answer", "")
            sources = state.get("qa_sources", [])
            confidence = state.get("qa_confidence", 0)

            response = f"ğŸ“š **å›ç­”**\n\n{answer}"

            if sources:
                response += "\n\n---\nğŸ“– **å‚è€ƒæ¥æº**"
                for src in sources[:3]:
                    response += f"\n- {src['file']} (ç¬¬{src['page']}é¡µ)"

            if confidence < 0.5:
                response += "\n\nâš ï¸ *æ³¨ï¼šç›¸å…³èµ„æ–™æœ‰é™ï¼Œå»ºè®®æŸ¥é˜…æ•™æç¡®è®¤ã€‚*"

        elif intent == IntentType.GENERATE_QUESTIONS:
            questions = state.get("generated_questions", [])
            chapter = state.get("chapter_info", "é€å¹³æœºæ¢°åŸç†")
            qtype = state.get("question_type", "ç»¼åˆ")

            response = f"ğŸ“ **{chapter} - {qtype}ç»ƒä¹ é¢˜**\n\n"

            for i, q in enumerate(questions, 1):
                if isinstance(q, dict):
                    if "raw_text" in q:
                        response += q["raw_text"]
                    else:
                        response += f"**ç¬¬{i}é¢˜** ({q.get('difficulty', 'ä¸­ç­‰')})\n"
                        response += f"{q.get('question', '')}\n"

                        if q.get('options'):
                            for opt in q['options']:
                                response += f"  {opt}\n"

                        response += f"\n<details>\n<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>\n\n"
                        response += f"**ç­”æ¡ˆ**: {q.get('answer', '')}\n\n"
                        response += f"**è§£æ**: {q.get('explanation', '')}\n\n"
                        response += f"**çŸ¥è¯†ç‚¹**: {q.get('knowledge_point', '')}\n"
                        response += f"</details>\n\n---\n\n"

        elif intent == IntentType.GRADE_HOMEWORK:
            grading = state.get("grading_result", {})

            score = grading.get("score", -1)
            level = grading.get("level", "æœªè¯„çº§")
            feedback = grading.get("feedback", "")
            correct = grading.get("correct_points", [])
            wrong = grading.get("wrong_points", [])
            suggestions = grading.get("suggestions", [])
            ref_answer = grading.get("reference_answer", "")

            if score >= 0:
                # æ ¹æ®åˆ†æ•°é€‰æ‹©emoji
                if score >= 90:
                    emoji = "ğŸŒŸ"
                elif score >= 80:
                    emoji = "ğŸ‘"
                elif score >= 70:
                    emoji = "ğŸ“ˆ"
                elif score >= 60:
                    emoji = "ğŸ’ª"
                else:
                    emoji = "ğŸ“š"

                response = f"{emoji} **ä½œä¸šæ‰¹æ”¹ç»“æœ**\n\n"
                response += f"**å¾—åˆ†**: {score}åˆ† ({level})\n\n"
                response += f"**æ€»è¯„**: {feedback}\n\n"

                if correct:
                    response += "âœ… **æ­£ç¡®ä¹‹å¤„**:\n"
                    for c in correct:
                        response += f"- {c}\n"
                    response += "\n"

                if wrong:
                    response += "âŒ **éœ€è¦æ”¹è¿›**:\n"
                    for w in wrong:
                        response += f"- {w}\n"
                    response += "\n"

                if suggestions:
                    response += "ğŸ’¡ **æ”¹è¿›å»ºè®®**:\n"
                    for s in suggestions:
                        response += f"- {s}\n"
                    response += "\n"

                if ref_answer:
                    response += f"ğŸ“– **å‚è€ƒç­”æ¡ˆ**:\n{ref_answer}"
            else:
                response = f"âŒ æ‰¹æ”¹å¤±è´¥: {feedback}"

        elif intent == IntentType.SUMMARY:
            summary = state.get("qa_answer", "")
            response = summary

        else:
            response = "ğŸ¤” æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£æ‚¨çš„æ„å›¾ã€‚æˆ‘å¯ä»¥å¸®æ‚¨ï¼š\n\n"
            response += "1. **å›ç­”é—®é¢˜** - ç›´æ¥æé—®é€å¹³æœºæ¢°ç›¸å…³çŸ¥è¯†\n"
            response += "2. **ç”Ÿæˆç»ƒä¹ é¢˜** - ä¾‹å¦‚ï¼šç»™æˆ‘å‡º5é“å…³äºè½´æµå¼å‹ç¼©æœºçš„é€‰æ‹©é¢˜\n"
            response += "3. **æ‰¹æ”¹ä½œä¸š** - ä¾‹å¦‚ï¼šå¸®æˆ‘æ‰¹æ”¹è¿™é“é¢˜ï¼š[æ‚¨çš„ç­”æ¡ˆ]\n"
            response += "4. **æ€»ç»“ç« èŠ‚** - ä¾‹å¦‚ï¼šæ€»ç»“ç¦»å¿ƒå¼å‹ç¼©æœºçš„çŸ¥è¯†ç‚¹\n"

        return {
            **state,
            "final_response": response
        }

    def _error_handler_node(self, state: AgentState) -> AgentState:
        """é”™è¯¯å¤„ç†èŠ‚ç‚¹"""
        error_msg = state.get("error_message", "æœªçŸ¥é”™è¯¯")

        return {
            **state,
            "final_response": f"å¤„ç†è¯·æ±‚æ—¶é‡åˆ°é”™è¯¯: {error_msg}\nè¯·ç¨åé‡è¯•æˆ–æ¢ä¸€ç§æ–¹å¼æé—®ã€‚"
        }

    # --------------------------------
    # è·¯ç”±å‡½æ•°
    # --------------------------------

    def _route_by_intent(self, state: AgentState) -> str:
        """æ ¹æ®æ„å›¾è·¯ç”±"""
        intent = state.get("intent", IntentType.UNKNOWN)
        confidence = state.get("intent_confidence", 0)

        if confidence < 0.3:
            return "error"

        route_map = {
            IntentType.QA: "qa",
            IntentType.GENERATE_QUESTIONS: "generate",
            IntentType.GRADE_HOMEWORK: "grade",
            IntentType.SUMMARY: "summary",
            IntentType.UNKNOWN: "qa"  # é»˜è®¤å½“ä½œé—®ç­”
        }

        return route_map.get(intent, "qa")

    def _route_after_retrieval(self, state: AgentState) -> str:
        """æ£€ç´¢åè·¯ç”±"""
        intent = state.get("intent", IntentType.QA)

        route_map = {
            IntentType.QA: "qa",
            IntentType.GENERATE_QUESTIONS: "generate",
            IntentType.SUMMARY: "summary"
        }

        return route_map.get(intent, "qa")

    # --------------------------------
    # å…¬å…±æ¥å£
    # --------------------------------

    def chat(
            self,
            user_input: str,
            session_id: str = "default",
            **kwargs
    ) -> Dict[str, Any]:
        """
        ä¸ Agent å¯¹è¯

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            session_id: ä¼šè¯ID
            **kwargs: é¢å¤–å‚æ•° (å¦‚ student_answer, reference_content)

        Returns:
            åŒ…å«å›å¤å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state: AgentState = {
            "user_input": user_input,
            "session_id": session_id,
            "intent": IntentType.UNKNOWN,
            "intent_confidence": 0.0,
            "chat_history": [],
            "retrieved_docs": [],
            "retrieved_images": [],
            "qa_answer": "",
            "qa_confidence": 0.0,
            "qa_sources": [],
            "chapter_info": kwargs.get("chapter_info", ""),
            "question_type": kwargs.get("question_type", "short_answer"),
            "question_count": kwargs.get("question_count", 5),
            "difficulty": kwargs.get("difficulty", "medium"),
            "generated_questions": [],
            "student_answer": kwargs.get("student_answer", ""),
            "reference_content": kwargs.get("reference_content", ""),
            "grading_result": {},
            "final_response": "",
            "error_message": ""
        }

        # é…ç½®ï¼ˆç”¨äºæ£€æŸ¥ç‚¹ï¼‰
        config = {"configurable": {"thread_id": session_id}}

        try:
            # è¿è¡Œ Graph
            final_state = self.app.invoke(initial_state, config)

            return {
                "response": final_state.get("final_response", ""),
                "intent": final_state.get("intent", IntentType.UNKNOWN).value,
                "confidence": final_state.get("qa_confidence", final_state.get("intent_confidence", 0)),
                "sources": final_state.get("qa_sources", []),
                "questions": final_state.get("generated_questions", []),
                "grading": final_state.get("grading_result", {}),
                "session_id": session_id
            }

        except Exception as e:
            logger.exception(f"Agent æ‰§è¡Œå‡ºé”™: {e}")
            return {
                "response": f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯: {str(e)}",
                "intent": "error",
                "confidence": 0.0,
                "sources": [],
                "session_id": session_id
            }

    def generate_questions(
            self,
            chapter: str,
            question_type: str = "short_answer",
            count: int = 5,
            difficulty: str = "medium"
    ) -> List[Dict[str, Any]]:
        """
        ç›´æ¥ç”Ÿæˆç»ƒä¹ é¢˜çš„ä¾¿æ·æ–¹æ³•

        Args:
            chapter: ç« èŠ‚åç§°
            question_type: é¢˜å‹ (choice/fill_blank/short_answer/calculation)
            count: é¢˜ç›®æ•°é‡
            difficulty: éš¾åº¦ (easy/medium/hard)
        """
        prompt = f"è¯·ç»™æˆ‘å‡º{count}é“å…³äº{chapter}çš„{question_type}ï¼Œéš¾åº¦ä¸º{difficulty}"

        result = self.chat(
            prompt,
            chapter_info=chapter,
            question_type=question_type,
            question_count=count,
            difficulty=difficulty
        )

        return result.get("questions", [])

    def grade_answer(
            self,
            student_answer: str,
            reference: str = ""
    ) -> Dict[str, Any]:
        """
        æ‰¹æ”¹ç­”æ¡ˆçš„ä¾¿æ·æ–¹æ³•

        Args:
            student_answer: å­¦ç”Ÿç­”æ¡ˆ
            reference: å‚è€ƒç­”æ¡ˆæˆ–è¯„åˆ†æ ‡å‡†
        """
        result = self.chat(
            f"è¯·æ‰¹æ”¹ä»¥ä¸‹ç­”æ¡ˆ: {student_answer}",
            student_answer=student_answer,
            reference_content=reference
        )

        return result.get("grading", {})


# ================================
# 4. ä½¿ç”¨ç¤ºä¾‹å’Œä¸»ç¨‹åº
# ================================

def create_agent_with_custom_model(
        kb_path: str,
        openai_api_key: str,
        openai_api_base: str = "https://api.zchat.tech/v1",
        model_name: str = "gpt-4o",
        custom_model_path: str = None
):
    """
    åˆ›å»ºå¸¦æœ‰è‡ªå®šä¹‰æ¨¡å‹çš„ Agent å·¥å‚å‡½æ•°

    Args:
        kb_path: çŸ¥è¯†åº“è·¯å¾„
        openai_api_key: API Key
        openai_api_base: API Base URL
        model_name: æ¨¡å‹åç§°
        custom_model_path: è‡ªå®šä¹‰å¾®è°ƒæ¨¡å‹è·¯å¾„ï¼ˆå¦‚æœæœ‰ï¼‰
    """
    # åˆ›å»º LLM
    llm = ChatOpenAI(
        openai_api_key=openai_api_key,
        openai_api_base=openai_api_base,
        model=model_name,
        temperature=0.3
    )

    # å¦‚æœæä¾›äº†è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„ï¼Œå¯ä»¥åŠ è½½æœ¬åœ°æ¨¡å‹
    # è¿™é‡Œé¢„ç•™æ¥å£ï¼Œç”¨æˆ·å¯ä»¥æ›¿æ¢ä¸ºè‡ªå·±çš„å¾®è°ƒæ¨¡å‹
    custom_llm = None
    if custom_model_path:
        # ç¤ºä¾‹ï¼šåŠ è½½æœ¬åœ°å¾®è°ƒæ¨¡å‹
        # from transformers import AutoModelForCausalLM, AutoTokenizer
        # custom_llm = YourCustomLLMWrapper(custom_model_path)
        logger.info(f"åŠ è½½è‡ªå®šä¹‰æ¨¡å‹: {custom_model_path}")
        pass

    # å°è¯•å¯¼å…¥å¹¶åˆ›å»ºçŸ¥è¯†åº“
    knowledge_base = None
    try:
        # è¿™é‡Œå‡è®¾ç”¨æˆ·å·²ç»æœ‰ MultiDocumentKnowledgeBase
        # å¯ä»¥ä»ç”¨æˆ·çš„åŸå§‹ä»£ç å¯¼å…¥
        logger.info(f"çŸ¥è¯†åº“è·¯å¾„: {kb_path}")
        knowledge_base = MultiDocumentKnowledgeBase(kb_path, openai_api_key)
    except Exception as e:
        logger.warning(f"çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°†åœ¨æ— çŸ¥è¯†åº“æ¨¡å¼ä¸‹è¿è¡Œ")

    # åˆ›å»º Agent
    agent = TurbineCourseAgent(
        knowledge_base=knowledge_base,
        llm=llm,
        custom_fine_tuned_llm=custom_llm
    )

    return agent


def main():
    """ä¸»ç¨‹åº - äº¤äº’å¼å‘½ä»¤è¡Œç•Œé¢"""
    print("=" * 60)
    print("é€å¹³æœºæ¢°åŸç†è¯¾ç¨‹æ™ºèƒ½åŠ©æ‰‹")
    print("åŸºäº LangGraph æ„å»º")
    print("=" * 60)

    # é…ç½®
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        print("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        return

    # åˆ›å»º LLM
    llm = ChatOpenAI(
        openai_api_key=openai_api_key,
        openai_api_base=os.getenv("OPENAI_API_BASE", "https://api.zchat.tech/v1"),
        model=os.getenv("MODEL_NAME", "gpt-5-1"),
        temperature=0.3
    )

    # åˆ›å»º Agent
    agent = TurbineCourseAgent(llm=llm)

    session_id = "demo_session"

    print("\nåŠŸèƒ½è¯´æ˜:")
    print("1. ç›´æ¥æé—® - å›ç­”é€å¹³æœºæ¢°ç›¸å…³é—®é¢˜")
    print("2. ç”Ÿæˆç»ƒä¹ é¢˜ - ä¾‹å¦‚ï¼šå‡º5é“è½´æµå¼å‹ç¼©æœºçš„é€‰æ‹©é¢˜")
    print("3. æ‰¹æ”¹ä½œä¸š - ä¾‹å¦‚ï¼šæ‰¹æ”¹ï¼šé€å¹³æ˜¯å°†...çš„æœºæ¢°")
    print("4. æ€»ç»“ç« èŠ‚ - ä¾‹å¦‚ï¼šæ€»ç»“ç¦»å¿ƒå¼å‹ç¼©æœº")
    print("\nè¾“å…¥ 'quit' é€€å‡º\n")

    while True:
        try:
            user_input = input("ğŸ‘¤ æ‚¨: ").strip()

            if not user_input:
                continue

            if user_input.lower() in ['quit', 'exit', 'q']:
                print("æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
                break

            print("\nğŸ¤– åŠ©æ‰‹: æ­£åœ¨å¤„ç†...\n")

            result = agent.chat(user_input, session_id=session_id)

            print(result["response"])
            print(f"\n[æ„å›¾: {result['intent']}, ç½®ä¿¡åº¦: {result['confidence']:.2f}]")
            print("-" * 60)

        except KeyboardInterrupt:
            print("\n\næ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
            break
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            print("-" * 60)


if __name__ == "__main__":
    main()
